{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python385jvsc74a57bd0055a310f58a1ab811f7fd85f388fd7463c92f0a3a43a1e2841d1b26142fb7dc4",
      "display_name": "Python 3.8.5 64-bit (conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXUYPQ-PkAjw"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from Method_timer import Method_timer"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLJ5_WvKkEFo"
      },
      "source": [
        "@Method_timer\n",
        "def train(net, epochs, trainloader, optimizer, criterion=nn.CrossEntropyLoss(), title=\"\", writer=None):\n",
        "    print(\n",
        "        f\"training {title} network for {epochs} epochs, {'tensorboard enabled' if writer else 'no tensorboard enabled'}\")\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            \n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            running_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                        (epoch + 1, i + 1, running_loss / 2000))\n",
        "                if writer:\n",
        "                    writer.add_scalar(\n",
        "                        'training loss, ' + title, running_loss/2000, epoch)\n",
        "                    writer.add_scalar('accuracy, '+title,\n",
        "                                        running_correct/2000, epoch)\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_correct = 0.0\n",
        "\n",
        "    print('Finished Training')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbRZ4GhIWEN2"
      },
      "source": [
        "def validate(net, testloader):\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    print(\"testing network:\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = net(inputs)\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print(\"total accuracy of net: %.2f%%\" % (correct/total*100))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpozCGqNkOvV"
      },
      "source": [
        "# Transform\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnVJ-dA2Vbc1",
        "outputId": "4ce1a3f4-6512-4ee2-d27e-774f5d657d51"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', \n",
        "                                        train=True,\n",
        "                                        download=True, \n",
        "                                        transform=transform_train)               \n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, \n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', \n",
        "                                       train=False,\n",
        "                                       download=True, \n",
        "                                       transform=transform_test)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, \n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "#writer = SummaryWriter()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwJSYP1RknUo",
        "outputId": "b3f8e390-f437-4fba-a4ab-63e5a3b107ec"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# ==== Alex Model ====\n",
        "\n",
        "alexnet_pretrained = torchvision.models.alexnet(pretrained=True) \n",
        "example, _ = data.next()\n",
        "    \n",
        "alexnet_pretrained.eval()\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-36-638a211af2b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0malexnet_pretrained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malexnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mexample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0malexnet_pretrained\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5fKQKoHlXon",
        "outputId": "18641ee4-3ae2-41d9-c1f4-c9eb0cca2be4"
      },
      "source": [
        "# Add an extra outputlayer with 10 outputs\n",
        "# Not sure how to add extra layer\n",
        "# Instead change the last layer to 10 outputs\n",
        "\n",
        "alexnet_pretrained.classifier[6] = nn.Linear(4096,10)\n",
        "alexnet_pretrained.eval()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlDhd73klGN8",
        "outputId": "d3b9787e-3c20-41f8-e41f-cac5cde5f15d"
      },
      "source": [
        "# === FineTunning ===\n",
        "\n",
        "alexnet_pretrained.to(device)\n",
        "alexnet_finetuning = alexnet_pretrained\n",
        "\n",
        "train(alexnet_finetuning,\n",
        "      epochs = 1,\n",
        "      trainloader = trainloader,\n",
        "      optimizer = optim.Adam(alexnet_finetuning.parameters(), lr = 0.001),\n",
        "      criterion = nn.CrossEntropyLoss(),\n",
        "      title = \"Fine Tuning AlexNet on CIFAR-10\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "timer() got an unexpected keyword argument 'epochs'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-39-17b435e8b94c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0malexnet_finetuning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malexnet_pretrained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m train(alexnet_finetuning,\n\u001b[0m\u001b[0;32m      7\u001b[0m       \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m       \u001b[0mtrainloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: timer() got an unexpected keyword argument 'epochs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KasUvoWownA",
        "outputId": "cf7937fd-5fc7-4746-ba32-f228fbed063d"
      },
      "source": [
        "# Validate\n",
        "validate(alexnet_finetuning, testloader)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing network:\n",
            "total accuracy of net: 10.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VODl_0gzo3CL",
        "outputId": "d0a5dcde-2ea4-467f-d075-2bd085b537e9"
      },
      "source": [
        "# === FineTunning ===\n",
        "\n",
        "alexnet_pretrained.to(device)\n",
        "alexnet_finetuning = alexnet_pretrained\n",
        "\n",
        "train(alexnet_finetuning,\n",
        "      epochs = 5,\n",
        "      trainloader = trainloader,\n",
        "      optimizer = optim.SGD(alexnet_finetuning.parameters(), lr=0.001, momentum=0.9),\n",
        "      criterion = nn.CrossEntropyLoss(),\n",
        "      title = \"Fine Tuning AlexNet on CIFAR-10\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training Fine Tuning AlexNet on CIFAR-10 network for 5 epochs, no tensorboard enabled\n",
            "[1,   200] loss: 2.302\n",
            "[1,   400] loss: 2.303\n",
            "[1,   600] loss: 2.303\n",
            "[1,   800] loss: 2.303\n",
            "[1,  1000] loss: 2.303\n",
            "[1,  1200] loss: 2.303\n",
            "[1,  1400] loss: 2.303\n",
            "[2,   200] loss: 2.303\n",
            "[2,   400] loss: 2.303\n",
            "[2,   600] loss: 2.303\n",
            "[2,   800] loss: 2.303\n",
            "[2,  1000] loss: 2.303\n",
            "[2,  1200] loss: 2.303\n",
            "[2,  1400] loss: 2.303\n",
            "[3,   200] loss: 2.303\n",
            "[3,   400] loss: 2.302\n",
            "[3,   600] loss: 2.303\n",
            "[3,   800] loss: 2.303\n",
            "[3,  1000] loss: 2.303\n",
            "[3,  1200] loss: 2.303\n",
            "[3,  1400] loss: 2.303\n",
            "[4,   200] loss: 2.303\n",
            "[4,   400] loss: 2.303\n",
            "[4,   600] loss: 2.303\n",
            "[4,   800] loss: 2.303\n",
            "[4,  1000] loss: 2.303\n",
            "[4,  1200] loss: 2.303\n",
            "[4,  1400] loss: 2.303\n",
            "[5,   200] loss: 2.303\n",
            "[5,   400] loss: 2.303\n",
            "[5,   600] loss: 2.303\n",
            "[5,   800] loss: 2.303\n",
            "[5,  1000] loss: 2.303\n",
            "[5,  1200] loss: 2.303\n",
            "[5,  1400] loss: 2.303\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJyr7vQ9vszQ",
        "outputId": "e193f018-6c0f-422c-db53-faeb712ef3c3"
      },
      "source": [
        "# Validate\n",
        "validate(alexnet_finetuning, testloader)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing network:\n",
            "total accuracy of net: 10.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXerAfJHvZuX",
        "outputId": "3637da9d-b94a-49ed-cd74-2da6e2109e57"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "            transforms.Scale(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', \n",
        "                                        train=True,\n",
        "                                        download=True, \n",
        "                                        transform=transform)               \n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, \n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', \n",
        "                                       train=False,\n",
        "                                       download=True, \n",
        "                                       transform=transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, \n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:285: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AajtEBR-vqUx",
        "outputId": "0cb7bd56-2c62-47b0-852b-749ab740b287"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "alexnet = torchvision.models.alexnet(pretrained=True) \n",
        "alexnet.classifier[6] = nn.Linear(4096,10)\n",
        "alexnet.eval()\n",
        "alexnet.to(device)\n",
        "\n",
        "train(net = alexnet,\n",
        "      epochs = 5,\n",
        "      trainloader = trainloader,\n",
        "      optimizer = optim.SGD(alexnet.parameters(), lr=0.001, momentum=0.9),\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "      )\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training  network for 5 epochs, no tensorboard enabled\n",
            "[1,  2000] loss: 1.266\n",
            "[1,  4000] loss: 0.911\n",
            "[1,  6000] loss: 0.791\n",
            "[1,  8000] loss: 0.711\n",
            "[1, 10000] loss: 0.678\n",
            "[1, 12000] loss: 0.623\n",
            "[2,  2000] loss: 0.478\n",
            "[2,  4000] loss: 0.478\n",
            "[2,  6000] loss: 0.492\n",
            "[2,  8000] loss: 0.485\n",
            "[2, 10000] loss: 0.487\n",
            "[2, 12000] loss: 0.470\n",
            "[3,  2000] loss: 0.321\n",
            "[3,  4000] loss: 0.312\n",
            "[3,  6000] loss: 0.334\n",
            "[3,  8000] loss: 0.344\n",
            "[3, 10000] loss: 0.325\n",
            "[3, 12000] loss: 0.344\n",
            "[4,  2000] loss: 0.211\n",
            "[4,  4000] loss: 0.209\n",
            "[4,  6000] loss: 0.236\n",
            "[4,  8000] loss: 0.243\n",
            "[4, 10000] loss: 0.249\n",
            "[4, 12000] loss: 0.257\n",
            "[5,  2000] loss: 0.143\n",
            "[5,  4000] loss: 0.163\n",
            "[5,  6000] loss: 0.160\n",
            "[5,  8000] loss: 0.201\n",
            "[5, 10000] loss: 0.183\n",
            "[5, 12000] loss: 0.211\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXJv1p8B8owe",
        "outputId": "b623701e-e1d0-498d-c926-e900b712440c"
      },
      "source": [
        "# Validate\n",
        "validate(alexnet, testloader)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing network:\n",
            "total accuracy of net: 83.77%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2dY_7m2-3Ot",
        "outputId": "e6aa9b65-4a2f-4933-e527-68991bfcfdc5"
      },
      "source": [
        "alexnet2 = torchvision.models.alexnet(pretrained=True) \n",
        "for param in alexnet2.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "alexnet2.classifier[6] = nn.Linear(4096, 10)\n",
        "alexnet2.to(device)\n",
        "\n",
        "train(net = alexnet2,\n",
        "      epochs = 5,\n",
        "      trainloader = trainloader,\n",
        "      optimizer = optim.SGD(alexnet2.parameters(), lr=0.001, momentum=0.9),\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "      )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training  network for 5 epochs, no tensorboard enabled\n",
            "[1,  2000] loss: 2.242\n",
            "[1,  4000] loss: 2.167\n",
            "[1,  6000] loss: 2.236\n",
            "[1,  8000] loss: 2.234\n",
            "[1, 10000] loss: 2.194\n",
            "[1, 12000] loss: 2.230\n",
            "[2,  2000] loss: 2.163\n",
            "[2,  4000] loss: 1.948\n",
            "[2,  6000] loss: 2.110\n",
            "[2,  8000] loss: 2.160\n",
            "[2, 10000] loss: 2.202\n",
            "[2, 12000] loss: 2.185\n",
            "[3,  2000] loss: 2.166\n",
            "[3,  4000] loss: 2.097\n",
            "[3,  6000] loss: 2.110\n",
            "[3,  8000] loss: 2.159\n",
            "[3, 10000] loss: 2.055\n",
            "[3, 12000] loss: 2.296\n",
            "[4,  2000] loss: 1.985\n",
            "[4,  4000] loss: 2.031\n",
            "[4,  6000] loss: 2.159\n",
            "[4,  8000] loss: 2.112\n",
            "[4, 10000] loss: 2.135\n",
            "[4, 12000] loss: 2.094\n",
            "[5,  2000] loss: 2.036\n",
            "[5,  4000] loss: 2.042\n",
            "[5,  6000] loss: 2.084\n",
            "[5,  8000] loss: 2.183\n",
            "[5, 10000] loss: 2.077\n",
            "[5, 12000] loss: 2.043\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNIGZubhWQ7L",
        "outputId": "c2b4a9a2-4542-469d-99c7-3c1befb48b98"
      },
      "source": [
        "validate(alexnet2, testloader)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing network:\n",
            "total accuracy of net: 73.90%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}